#!/usr/bin/env python3
"""Use the OpenAI API to look up Wikidata QIDs.

This script queries the OpenAI Responses API for every animal in the
local database that is missing a ``wikidata_qid``.  The model is asked to
provide the correct Wikidata item identifier (``QID``) for the species
given its original Latin name as well as its German and English common
names.  The model must return ``null``/``unknown`` if no Wikidata entry is
found.  Returned identifiers are written back to the database only if no
other animal already uses the same QID.

The heavy lifting is delegated to :func:`process_animals` which accepts an
optional OpenAI client instance for easier testing.
"""
from __future__ import annotations

import argparse
import asyncio
from pathlib import Path
import re
import sqlite3
import time
from typing import Any, Callable, Optional

from matcher_shared import (
    apply_qid_update,
    ensure_enrichment_columns,
    fetch_wikidata_enrichment,
    lookup_rows as lookup_rows_async,
    RESET_COLS,
)

try:  # pragma: no cover - fallback for environments without python-dotenv
    from dotenv import load_dotenv
except Exception:  # pragma: no cover - library missing
    import os

    def load_dotenv(*args, **kwargs):  # type: ignore
        dotenv_path = kwargs.get("dotenv_path") if kwargs else None
        override = kwargs.get("override", False)
        if not dotenv_path:
            return False
        try:
            with open(dotenv_path, "r") as fh:
                for line in fh:
                    line = line.strip()
                    if not line or line.startswith("#"):
                        continue
                    key, _, value = line.partition("=")
                    if key and (override or key not in os.environ):
                        os.environ[key] = value
            return True
        except OSError:
            return False
try:  # pragma: no cover - allow running without pydantic
    from pydantic import BaseModel
except Exception:  # pragma: no cover - library missing
    class BaseModel:  # type: ignore
        pass
from zootier_scraper_sqlite import DB_FILE, ensure_db_schema

load_dotenv(dotenv_path=Path(__file__).resolve().parent / ".env", override=False)


class WikidataLookup(BaseModel):
    """Structured output parsed from the model response."""

    wikidata_qid: str | None = None

class BreedLookup(BaseModel):
    """Structured output for domesticated form / breed lookup."""
    wikidata_qid: str | None = None
    wikipedia_en: str | None = None  # page title OR full URL accepted
    wikipedia_de: str | None = None  # page title OR full URL accepted


_QID_RE = re.compile(r"^Q\d+$")


def update_enrichment(
    cur: sqlite3.Cursor, art: str, qid: str, fetch: Callable[[str], dict[str, str]] = fetch_wikidata_enrichment
) -> None:
    """Fetch metadata for *qid* and store it for *art*."""

    data = fetch(qid)
    # Enforce uniqueness for wikipedia_* before writing
    def _is_unique(col: str, title: str) -> bool:
        if not title:
            return False
        cur.execute(f"SELECT art, klasse FROM animal WHERE {col}=? AND art<>?", (title, art))
        row = cur.fetchone()
        if not row:
            return True
        # If someone else already has this link, we keep theirs—especially if klasse<6
        return False

    update = {}
    for k, v in data.items():
        if not v:
            continue
        if k == "parent_taxon" and v == "":
            continue
        if k in ("wikipedia_en", "wikipedia_de"):
            if _is_unique(k, v):
                update[k] = v
        else:
            update[k] = v
    if not update:
        return
    set_bits = ", ".join(f"{k}=?" for k in update)
    cur.execute(f"UPDATE animal SET {set_bits} WHERE art=?", (*update.values(), art))


def _normalize_wiki_title(value: Optional[str]) -> Optional[str]:
    """Accept a Wikipedia page title OR full URL and return a canonical page title (spaces, decoded)."""
    if not value:
        return None
    val = value.strip()
    if not val:
        return None
    # URL form: https://XX.wikipedia.org/wiki/Page_Title or /w/index.php?title=...
    import urllib.parse as _u
    if "wikipedia.org" in val:
        try:
            # Extract after '/wiki/' or from query param 'title'
            if "/wiki/" in val:
                page = val.split("/wiki/", 1)[1]
            else:
                qs = _u.urlparse(val).query
                qp = dict(_u.parse_qsl(qs))
                page = qp.get("title")
            if not page:
                return None
            page = _u.unquote(page)
            page = page.replace("_", " ").strip()
            return page or None
        except Exception:
            return None
    # Otherwise assume it's already a title
    return val.replace("_", " ").strip() or None

def lookup_breed(
    client: Any,
    latin: str,
    name_de: Optional[str],
    name_en: Optional[str],
) -> tuple[Optional[str], Optional[str], Optional[str]]:
    """Query the OpenAI API for a DOMESTICATED FORM / BREED.
    Returns (qid, wikipedia_en_title, wikipedia_de_title).

    Parameters
    ----------
    client:
        An object exposing ``responses.parse`` compatible with the OpenAI
        Python SDK.
    latin, name_de, name_en:
        Names used to query the model. The latin name may match the wild form;
        prefer domesticated/breed items.
    """

    prompt = (
        "You are matching DOMESTICATED FORMS / BREEDS of animals (not the wild species). "
        "Given the names below, return:\n"
        "• wikidata_qid: The QID for the domesticated form OR specific breed (NOT the wild species item). If none exists, return null.\n"
        "• wikipedia_en: The exact EN Wikipedia page title or URL for the domesticated form/breed, if such a page exists; otherwise null.\n"
        "• wikipedia_de: The exact DE Wikipedia page title or URL for the domesticated form/breed, if such a page exists; otherwise null.\n"
        "Rules:\n"
        "– Prefer items explicitly describing domestication/breed (e.g., 'Domestic cat', 'Domestic yak', 'Siamese cat').\n"
        "– Do NOT return the wild species page/item.\n"
        "– If multiple breeds exist, pick the one that best matches the provided common names; otherwise pick the general domesticated form.\n"
        "– If unsure, return null.\n\n"
        f"Latin (may match wild taxon): {latin}\n"
        f"German common/breed name: {name_de or 'unknown'}\n"
        f"English common/breed name: {name_en or 'unknown'}\n"
    )
    client_opt = (
        client.with_options(timeout=900.0)
        if hasattr(client, "with_options")
        else client
    )
    for attempt in range(3):
        try:
            resp = client_opt.responses.parse(
                model="gpt-5-mini",
                input=[
                    {
                        "role": "system",
                        "content": (
                            "You find Wikidata QIDs for DOMESTICATED FORMS / BREEDS of animals, "
                            "and their EN/DE Wikipedia page titles when available. "
                            "Return null for fields that do not exist."
                        ),
                    },
                    {"role": "user", "content": prompt},
                ],
                tools=[{"type": "web_search"}],
                reasoning={"effort": "minimal"},
                service_tier="flex",
                text_format=BreedLookup,
            )
            out = resp.output_parsed
            raw_qid = (out.wikidata_qid or "").strip()
            qid = None
            if raw_qid and raw_qid.lower() not in {"none", "null", "unknown"} and _QID_RE.match(raw_qid):
                qid = raw_qid
            wiki_en = _normalize_wiki_title(out.wikipedia_en)
            wiki_de = _normalize_wiki_title(out.wikipedia_de)
            return qid, wiki_en, wiki_de
        except Exception as exc:  # pragma: no cover - network faults
            status = getattr(exc, "status_code", None)
            if status in {408, 429} and attempt < 2:
                time.sleep(2**attempt)
                continue
            raise
    return None, None, None


def _update_wikipedia_links_if_unique(cur: sqlite3.Cursor, art: str, wiki_en: Optional[str], wiki_de: Optional[str]) -> None:
    """Write wikipedia_en/de if present AND unique across the table."""
    updates = {}
    if wiki_en:
        cur.execute("SELECT art, klasse FROM animal WHERE wikipedia_en=? AND art<>?", (wiki_en, art))
        row = cur.fetchone()
        if not row:
            updates["wikipedia_en"] = wiki_en
    if wiki_de:
        cur.execute("SELECT art, klasse FROM animal WHERE wikipedia_de=? AND art<>?", (wiki_de, art))
        row = cur.fetchone()
        if not row:
            updates["wikipedia_de"] = wiki_de
    if updates:
        set_bits = ", ".join(f"{k}=?" for k in updates)
        cur.execute(f"UPDATE animal SET {set_bits} WHERE art=?", (*updates.values(), art))


async def _process_animals_async(
    db_path: str = DB_FILE,
    client: Any | None = None,
    lookup: Callable[
        [Any, str, Optional[str], Optional[str]],
        tuple[Optional[str], Optional[str], Optional[str]],
    ] | None = None,
    *,
    concurrency: int = 30,
) -> None:
    """Process all domesticated animals and update their ``wikidata_qid`` values."""

    if client is None:  # pragma: no cover - exercised only in manual runs
        from openai import OpenAI  # type: ignore

        client = OpenAI(timeout=900.0)

    if lookup is None:
        lookup = lookup_breed

    conn = sqlite3.connect(db_path)
    ensure_db_schema(conn)
    ensure_enrichment_columns(conn)
    cur = conn.cursor()
    cur.execute(
        """
        SELECT art, latin_name, name_de, name_en
        FROM animal
        WHERE klasse = 6
          AND wikidata_qid IS NULL
          AND zoo_count > 0
        ORDER BY zoo_count DESC
        """
    )
    rows = cur.fetchall()

    existing_qids = {
        qid
        for (qid,) in cur.execute(
            "SELECT wikidata_qid FROM animal WHERE wikidata_qid IS NOT NULL"
        )
        if qid
    }
    existing_wiki_en = {
        t
        for (t,) in cur.execute(
            "SELECT wikipedia_en FROM animal WHERE wikipedia_en IS NOT NULL"
        )
        if t
    }
    existing_wiki_de = {
        t
        for (t,) in cur.execute(
            "SELECT wikipedia_de FROM animal WHERE wikipedia_de IS NOT NULL"
        )
        if t
    }
    cols = {row[1] for row in cur.execute("PRAGMA table_info(animal)")}
    clear_cols = tuple(c for c in RESET_COLS if c in cols)

    print(f"{len(rows)} animals to process")
    async for (art, latin, name_de, name_en), (qid, wiki_en, wiki_de) in lookup_rows_async(
        rows,
        client,
        lookup,
        concurrency=concurrency,
        fail_value=(None, None, None),
    ):
        print(f"Processing {art} ({latin})")
        if qid and qid in existing_qids:
            print(f" -> collision on QID {qid}; skipping")
            continue
        if wiki_en and wiki_en not in existing_wiki_en:
            _update_wikipedia_links_if_unique(cur, art, wiki_en, None)
            existing_wiki_en.add(wiki_en)
        if wiki_de and wiki_de not in existing_wiki_de:
            _update_wikipedia_links_if_unique(cur, art, None, wiki_de)
            existing_wiki_de.add(wiki_de)
        if qid:
            apply_qid_update(
                cur,
                art,
                qid,
                status="llm",
                reset_fields=False,
                clear_cols=clear_cols,
            )
            update_enrichment(cur, art, qid)
            existing_qids.add(qid)
            print(f" -> assigned QID {qid}")
        else:
            print(" -> no QID found")
        conn.commit()

    conn.close()


def process_animals(
    db_path: str = DB_FILE,
    client: Any | None = None,
    lookup: Callable[
        [Any, str, Optional[str], Optional[str]],
        tuple[Optional[str], Optional[str], Optional[str]],
    ] | None = None,
    *,
    concurrency: int = 30,
) -> None:
    """Synchronous wrapper for :func:`_process_animals_async`."""

    try:
        asyncio.run(
            _process_animals_async(
                db_path=db_path,
                client=client,
                lookup=lookup,
                concurrency=concurrency,
            )
        )
    except RuntimeError:  # event loop already running
        loop = asyncio.get_event_loop()
        loop.run_until_complete(
            _process_animals_async(
                db_path=db_path,
                client=client,
                lookup=lookup,
                concurrency=concurrency,
            )
        )


if __name__ == "__main__":  # pragma: no cover - manual invocation
    parser = argparse.ArgumentParser()
    parser.add_argument("--concurrency", type=int, default=30)
    args = parser.parse_args()
    process_animals(concurrency=args.concurrency)
